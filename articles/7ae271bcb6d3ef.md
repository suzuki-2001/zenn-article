---
title: "BERTをバイオインフォマティクスに応用した研究　-DNA BERT-"
emoji: "🦁"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["DNABERT","Bioinfomatics"]
published: true
---
## はじめに
本記事ではDNA-BERTと呼ばれる論文について紹介します。詳しい結果は論文か、[こちらの記事](https://ai-scholar.tech/articles/bioinformatics/dnabert)も参考にしてみてください。

## DNA-BERTとは
DNA-BERTはその名前の通り、DNA配列にBERTを適用した技術です。[こちらの論文](https://doi.org/10.1093/bioinformatics/btab083)にて紹介されており、生命科学×自然言語処理の本格的な研究としてはかなり早い段階での実装となります。入力配列をK-merによってトークン分割し、もう一つ、その配列の15%ほどをマスクしたものとセットで事前学習を行います。そしてファインチューニングを行うことによって、DNA配列のタスクに対して高い精度を出すことができるというものです。

[GitHub](https://github.com/jerryji1993/DNABERT)はこちら

## ファインチューニングと各タスク
本論文では以下の３つのタスクを中心にその精度を検証しています。

1. 近位プロモーター領域の推定
真核生物においてはTATAボックスが例として挙げられます。私たちの持つタンパク質をコードする遺伝子は、転写開始部位の前にTATAボックスと呼ばれる特徴的なヌクレオチド配列を持っています。この配列は通常 T-A-T-A-a/t-A-a/t のようになっています（ここで、a/t は A または T どちらが来ても構わないことを意味します）。本タスクでは、このTATAボックスをポジティブとする二値分類タスクとなっています。
<br>

2. 転写因子結合部位の予測
ここでは基本転写因子の結合部位を予測します。転写因子の結合については[こちらの記事](https://sato-ayumi.com/2019/06/11/%E7%9C%9F%E6%A0%B8%E7%B4%B0%E8%83%9E%E3%81%AE%E8%BB%A2%E5%86%99%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%9F%BA%E6%9C%AC%E8%BB%A2%E5%86%99%E5%9B%A0%E5%AD%90%E3%81%AE%E5%83%8D%E3%81%8D%E3%82%92%E3%82%8F/) が非常にわかりやすいです。ここではENCODEデータベース(CHIP-seq)を用いてファインチューニングを行っています。
<br>
3. 選択的スプライシングによる絵既存結合部位予測
スプライシングはDNAから転写されたmRNA前駆体に含まれるタンパク質合成に不必要な部分（イントロン）を除き、必要な部分（エキソン）を連結する反応です。このエキソンが結合する部位がスプライス部位です。このタスクではスプライス部位における5'末端（ドナー）と3'末端（アクセプター）、および非スプライス部位という3クラス分類を行います。<br>


これらの検証結果をまとめると、DNA-BERTは全てのタスクにおいて既存手法のスコアをうわまりました。使用されたデータセットが不均衡データだったので、既存手法ではMCCのスコアが正解率と比較して大きく低下しましたが、DNA-BERTは比較的高いスコアを維持しており、不均衡データに対してもロバストであることがわかります。

## AttentionがDNA配列に対しても機能する？
ここが本題です。既存の手法でもトークン化はK-merが使用されることが多く、モデルにCNNやRNNが採用されます。事前学習を十分に行った言語モデルであれば、DNA配列に関するタスクにおいても既存手法のパフォーマンスを上回ることはある程度想像がつきます。しかし、AttentionがDNA配列に対しても機能するのか？という点については、少し疑問が残ります。Attentionは言語モデルの学習において、文脈を考慮した単語の重要度を計算するために使用されます。DNA配列には語彙も文脈もないので、Attentionが機能しているのかがこの論文でのもう一つのトピックといえます。

### TAp73-beta BS
![TAp73-beta](/images/dna_bert/Tap73-beta.png)
*TAp73-beta因子の結合部位予測の可視化*
こちらはTAp73-betaと呼ばれる転写因子の結合部位予測の結果を示しています。TAp73-betaはp53のアイソフォームの転写因子で、がん抑制因子として知られています。この図は、DNA-BERTがどのようにAttentionを用いて予測を行っているかを示しています。これをみると上2つの結合部位ではAttentionの数値が比較的高くなっていることが確認できますが、一番下の結合部位ではない場所では、Attentionスコアは低くなっています。詳細な原理は不明ですが、Attentionは確かにDNA配列の何かしらの特徴を掴んでいると考えられます。

### P53 BS
![The importance of pre-training & fine-tuning](/images/dna_bert/attention-map.png)
*事前学習とファインチューニンングの重要性*
こちらも先ほどの例と同様にP53転写因子の結合部位予測の可視化です。今度はランダム初期化と事前学習、ファインチューニングの有無で予測結果がどう変化するのかを確認しています。事前学習のみでも明確にAttentionのスコアに勾配がつき、ファインチューニングによってさらにスコアが上昇していることがわかります。これは、DNA配列に対しても事前学習が有効であることを示しています。DNA配列も自然言語と同様に、文法や語彙など共通の性質を持ち、多様な言語と同様に各タスク特有の特徴を持っているのかもしれません。

### ENCODE 690 CHIP-seq 
![ENCODE 690 CHIP-seq](/images/dna_bert/logor.png)
*機能的変異の検出*
こちらはENCODE 690 ChIP-seqデータセットを用いた機能的バリアントの検出例です。野生型と比較して変異型は中央に4bpの欠失が確認できます。この病原性4bp欠失は非常に稀な変異であり、難聴を特徴とする常染色体劣性アッシャー症候群の原因として知られています。こうした変異の検出においても、Attentionが機能していることが確認できます。DNA-BERTは想像よりも幅広い領域での応用が可能なのかもしれません。

## 最後に
本記事では簡単にDNA-BERTと呼ばれる論文について紹介しました。まだ実用性などの議論をするには早いですが、技術としてはかなり興味深いと思います。また、DNA配列が我々の想定以上に自然言語に似た性質を持っているかもしれないこと、Attentionが自然言語以外にも強力な手法であるかもしれないことなど、さまざまな可能性が考えられます。こうした論文は、2022年~から急激に増えているので、今後の動向に注目です。

これは著者の意見ですが、この手の研究はデータドリブンの研究者には刺さりますが、ウェット実験が中心の研究者からは好まれないことがあります。BERTが何者なのかがよくわかっていなかったり、MLのタスクにどれだけ実用的な意味があるのか少し疑いの目を持っていたりするようです。しかし、こういった分野横断的な研究が未知の領域を切り開き、将来的に既存のツールを凌ぐ精度で実装される可能性はあると思います。実用的な意義はもちろん重要ですが、こうした新しい発想を試した人はいなかったので、とりあえずやってみるというようなスタンスも重要な気がしています。

